---
title: "scATAC-seq Notebook"
author: "Cassandra Burdziak"
date: "January 27, 2017"
output: 
  pdf_document:
    fig_width: 2
    fig_height: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
Document originally created January 23rd, 2017.  Transferred to R Markdown file on January 27th, 2017.

##January 10-January 22 (retrospective notes):

1. Used DHS matrices provided in the tarball on GEO to reproduce Jaccard distances multidimensional scaling. I was able to reproduce them perfectly except the direction for the HL-60 vs. GM12878 figure was a mirror image of the original (irrelevant because sign is arbitrary with the distance function).

2. Wrote pipeline to align, process (sort, remove mitochondrial reads, remove duplicate reads, covert formats to bam), and call peaks on single-cell ATAC-seq reads. Ran pipeline on the HEK293T vs GM12878 and HL-60 vs GM12878 (not the control set) datasets on SRA.

3. Wrote custom python script which uses output sam file, peak file, and file provided by the authors which maps barcodes to each read name to create matrix of peak read count by cell. Used the “Updated” barcode name in this index conversion file, and removed any reads which contained a “CTF” or “AMBIG” element in the updated barcode. These were selected for by removing reads whose barcodes contained an underscore.  Reads corresponding to barcodes for which there were fewer than 500 reads were also excluded.

4. Modified R script to create Jaccard distance multidimensional scaling to be used on the output of my script to produce matrix of peak read count per cell.
Modified R script for Jaccard distance multidimensional scaling to be only consider subtypes of GM12878 (by subsetting only cells who were given this assignment in the paper) and to include k-means procedure on the data in this matrix.  A script was also written to perform k-means on the features from Jaccard distance multidimensional scaling, and to create a heat map of these components from multidimensional scaling.

5. To see whether read count per cell was correlated with coordinate one in Jaccard distance multidimensional scaling, modified python script to produce a read count per cell in the final set of cells and wrote out to file.  Added some code to R scripts to import this file and plot the log (base 10) of these values against the output coordinate 1 from multidimensional scaling using Jaccard distances.


##January 23rd
1. Aligned SRR1947694 and SRR1947695, the two Control sets of GM12878 and HL-60 mixtures, and processed + called peaks using Homer.

2. Modified scATAC_jaccardclustering_DHSmatrix.R to include code for subsetting the full DHS matrix file for GM12878 and HL-60 mixtures (the original set, not one of the controls) to include only GM12878 cells and to perform Jaccard distance multidimensional scaling to see subtype clusters.  No very distinct subtype clusters were found but more were found than with only ATAC-seq peaks. Github updated.


![Multidimensional scaling on Jaccard distances between cell subtypes of GM12878, data from Cusanovich et al.](/Users/cass/Documents/LeslieLab/NewAnalysis/GM12878subtypes_Jaccard_DHSpeaks.pdf)


3.  Wrote R script to handle large merged DHS site matrix from the three control studies.  Major difference from previous code is that it has different indexing to create barcode data frame and uses read count files for all three control sets at once.  Does both the full Jaccard clustering and the subtype clustering.

4. I had accidentally forgotten to re-submit the alignment for SRR1947695 after killing the job due to an error I found in the shell script.  I re-submitted it now.  SRR1947696 is also now aligned, processed, and has had peaks called with Homer.  Downloading to local machine so that the alignments and peak bed files may be used to create the peak matrices with my custom script.

5. Preliminary, but it appears that the number of cells I am able to find in the DHS matrices that are provided on GEO for the three control experiments differs from that which is reported in the paper.  I am so far seeing 13835.  I will inspect this more tomorrow.

##January 24th

1. Alignment for SRR1947695 failed because I accidentally left the fastq files gzipped and the rsync failed. Unzipped them and resubmitted the job.

2. Downloaded peak files to local machine for SRR1947694 and SRR1947696.  When attempting to create peak matrix with custom script, a key error is thrown when looking up a read name in the barcode dictionary. It was subsequently discovered that the index conversion file provided by the authors does not contain as many read names as there are in the sam file.  Precisely, a key error is thrown for read SRR1947696.19242073 and there are only 16676421 reads in the index conversion file. I re-downloaded the index conversion file and checked the alignment script to ensure that there had not been a mix-up on my part.  Correct mapping between SRA and index files was also checked on GEO. Did a grep for one of the missing read names in the original fastq files and it is definitely there.

3. Created SRR1947696 matrix with missing reads.  Saved as PeakMatrix_Ctl3.csv. Accidentally wrote over the original peak matrix file for the HEK293T vs GM12878 dataset but it can be recreated easily with the script if needed.

4. Saved binary R files for complete and subsetted GM12878 matrix to hopefully reduce time to import and process data.

##January 25th

1. Alignment completed for SRR1947695 last night.  Files saved on server.

2. Saved new binary R fine CtlSetMerged.dhsmatrix.GM12878only.reduced.RDS which contains the DHS peak file with only cells labelled as GM12878 and without any cells with < 400 sites and sites used in < 150 cells (as in the paper).  Actually I believe there is a mistake since it has the same number of elements as the GM12878 matrix.  Using sapply with as.numeric is very slow but I think it will be necessary to subset rows/columns by a numeric value.

##January 26th

1. I uploaded CtlSetMerged.dhsmatrix.GM12878only.RDS to the server and wrote a script in R to read this in, convert all entries to numerics, subset the rows/columns, and save it is a new file. Even having done this on a 100GB node, R threw an exception at a single vector being > 80Gb.  I have resorted to using a python script to remove these columns and rows on the original (containing both GM12878 and HL-60 entries) CtlSetMerged.dhsmatrix.txt file.  I discovered that their were additional columns with strings (‘Gmspecific’) in the middle of the file which had been a problem for the R row and column summation all along (these were a result of the merge in pandas).  The python script was written so that the output would not include these columns.

2. Found that some part of the sam file for SRR1947695 must have failed to download to local machine because file is much larger on server than on local machine. 

3. In creating the data matrix for SRR1947694, finished first half of script (prior to adding header, converting to bam, and indexing) yesterday and then wrote over keeplist variable in producing SRR1947695.  I am still using the barcodes_500 output sam for SRR1947694 from yesterday but re-generating keeplist by running code again.  This should not have any effect on the output.

4. Performed t-sne using Jaccard distance matrix as input on GM12878 vs. HL-60 dataset (SRR1947693) and GM12878 vs. HEK293T dataset (SRR1947692) using the DHS matrix files produced by the authors.  Got very good separation between the cell types with this method, which was used by Dr. Ren’s lab from UCSD first and was introduced to us this week at a talk he gave.

![t-SNE on Jaccard distances between cells in mixture of HL-60 and GM12878 (SRR1947693), processed data from Cusanovich et al.](/Users/cass/Documents/LeslieLab/NewAnalysis/GM12878vsHL60_jaccardtsne.pdf)

![t-SNE on Jaccard distances between cells in mixture of HEK293T and GM12878 (SRR1947692), processed data from Cusanovich et al.](/Users/cass/Documents/LeslieLab/NewAnalysis/GM12878vsHEK293T_jaccardtsne.pdf)

5. Had to remake de novo ATAC-seq peak matrices from existing bam files (re-generating the keeplist each time) as they had been written over accidentally.  Then performed the same analysis as above (t-sne with Jaccard distance input) on my own de novo peaks. I found that clustering is not as useful when using t-sne with the Jaccard distances on the de novo peaks.  For instance, without the labels in the HL-60 vs. GM12878 plot, it would be unclear how many cell types are present.  Still, the cells are separated fairly reliably.  

![t-SNE on Jaccard distances between cells in mixture of HL-60 and GM12878 (SRR1947693), de novo peaks called on raw data from Cusanovich et al.](/Users/cass/Documents/LeslieLab/NewAnalysis/GM12878vsHL60_jaccardtsne_denovopeaks.pdf)

![t-SNE on Jaccard distances between cells in mixture of HEK293T and GM12878 (SRR1947692), de novo peaks called on raw data from Cusanovich et al.](/Users/cass/Documents/LeslieLab/NewAnalysis/GM12878vsHEK_jaccardtsne_denovopeaks.pdf)

6. Completed subsetting rows and columns with python script in merged control sets of both HL-60 and GM12878 cell populations.  I realized that I will need the original columns with the original indexing for the GM12878 subsetting to work.  I will have to modify the R code to subset the file CtlSetMerged.dhsmatrix.rowreduced.csv, map these to cell type first, and then use a tab-delimited one line file of booleans for the columns that should be kept in columnsbool.txt to choose the columns to keep.  Then I can subset the GM12878 cells. 

##January 27th

1. Needed to do a complete re-do of the python subsetting script.  In the end I just decided to use the cut function in unix to remove the problematic columns containing the “Gmspecific” entries.  This will not affect the results of the analysis; the goal of the python and R scripts was to do this in addition to reformatting, but it is easiest at this point to do it from command line.  Used the following commands to extract the columns which contained data and concatenated them back together:

```
cut -d, -f1-4543 CtlSetMerged.dhsmatrix.txt > one.txt
cut -d, -f4545-9125 CtlSetMerged.dhsmatrix.txt > two.txt
cut -d, -f9127-13840 CtlSetMerged.dhsmatrix.txt > three.txt
paste -d, one.txt two.txt three.txt > CtlSetMerged.dhsmatrix_dataonly.txt
```

Then used python script to convert to integers, remove rows which were too sparse using the criteria specified in Cusanovich et al.  Wrote an R script following this to retain only GM12878 cells and to subset columns.  It should be noted that the cell counts and site counts differ from what the authors ended up with even though the same criteria was used, but there was also a discrepancy with the cell count in the original (unfiltered) DHS peak files vs. what they state is the total cell count in the paper.  It is currently unclear what accounts for this discrepancy.  Precisely, we end up with 35526 rows (sites) retained in the matrix and 4705 columns (cells) when all subsetting for small count cells/sites is done and only GM12878 cells are retained.

2. Used bedtools to merge retained sites with usage in > 150 cells with the Broad’s chromHMM GM12878 browser data obtained from the table browser on UCSC genome browser for hg19.  The command used was as follows:

```
bedtools intersect -a CtlSetMerged.dhsmatrix.GMfullyreduced.sites.sorted.bed -b hg19chromHMM.bed -wa -wb  > CtlSetMerged.dhsmatrix.GMfullyreduced.annotated_sites.bed 
```

The result is a file which contains the original site coordinates repeated for as many times as they had any overlap with the chrommHMM annotations.  The resulting file was around double the original file (77340 lines) indicating that on average there were around 2 overlaps with chromHMM annotations per site.  This was unfortunately high, since we hoped to map each site unambiguously to a chromatin class.

3. Wrote a script in R to perform a t-sne with Jaccard distances on the merged control matrix of DHS peaks from the authors. The intersected accessible site and chromHMM annotation file was read in.  The unique() function was used to remove duplicates for each site such that whichever of multiple annotations per site occurred first was assigned to that site.  This is an unideal solution.  In the future I should look into how dissimilar the annotations were per site to see if this is really viable.  This is only meant to be a first approximation.  The script then calculates pairwise Jaccard distances between each of the cells and plots a t-sne based on these distances.  It does the same for distances between cells and colors the plot based on the assignment to each annotation type.

4. Yesterday I updated the file names on github and ended up just creating entirely new files instead of committing to the original ones.  All the commits I have up until yesterday were deleted.  This is fine since all the new files are working properly and should include all the code I used to generate each of the figures I have retained up to this point.

5. Modified code for generating peak matrix from de novo peaks for control files to include the coordinates of the peaks in the output.  The output matrix will also be transposed compared to the original form (it will now be the same as the DHS peak matrices from the authors, with the rows corresponding to sites and the columns corresponding to cells).  

##January 30th

1. Executed binary distance function (from amap) in R on the Weill Cornell server and simulataneously running the jaccard distance function (from proxy) on my local machine for the GM12878-only merged control file (merged matrix of authors data on GEO) of DHS sites vs. cells.  Time to compute distance matrix is very long. 

2. Jaccard distance function from proxy seemed to finish much faster on local machine then the binary distance calculation on amap.  I ran a t-sne on this distance matrix and discovered that there are no identifiable cell subtypes.  I should repeat this using only GM12878 peaks.

![t-SNE on Jaccard distances of GM12878 cells only in matrix of cells in control experiments versus cell-type specific DHS peaks, merged matrix of processed data from Cusanovich et al. ](/Users/cass/Documents/LeslieLab/NewAnalysis/GM12878subtypes_tsne_ctlset.pdf)

3. Edited python code for subsetting sites with usage in < 150 cells to also subset non-GM12878 specific sites.  Running this on the server to produce a new file CtlSetMerged.dhsmatrix.rowreduced_gmonly.csv which will then need to be downloaded and passed to the same R script for removal of the appropriate columns.

4. Edited R code for subsetting cells < 400 sites used AND non-GM12878 cells to *retain* the non-GM12878 cells.  In other words, the output includes both HL-60 and GM12878 cell mixtures.  This will allow me to test whether the existing clustering methods can separate out the cell types, since so far with t-sne they are failing to separate out cell subtypes.

5.  Currently running 2 jobs on the server: one will produce the distance matrix for all sites with only GM12878 cells; the other will produce distance matrices for both sites and cells with mixtures of GM12878 cells and HL-60 cells.  Also running a job for the python script to output row reduced CSV with only GM12878 specific sites; the output of this script will need to be passed to the R script for further reduction for only the GM12878 cell subtypes. Distance matrices will then need to be produced for these. In the end I will have six distance matrices ,3 for cells ad 3 for sites, corresponding to the following mixtures of cells/sites: GM12878 subtypes with all DHS sites, GM12878 subtypes with only GM12878-specific sites, GM12878/HL-60 mixture with all DHS sites. All will be subsetted to remove cells/sites with little data.

##January 31st
1. It appears as though something went wrong with the python script to reduce the rows of the merged control matrix by both cell usage count and GM12878-specificity as only 3311 rows were retained. I performed a grep on the original matrix file (not subsetted at all) to pull out rows which contained a "Gmspecific" or "Hlspecific" annotations into two repsective files.  The total number of sites in these files was 142713 (88561 HL-60 specific and 54152 GM12878 specific) out of 221000 lines total. To identify the source of all these missing sites, I created a file which contains lines with neither "Gmspecific" or "Hlspecific" annotations. This file contained 78287 lines, which is the expected number of un-annotated lines based on the numbers above.  Discovered that there are a number of sites annotated as "Common" in the dataset.  I wish to include these in the matrix for the analysis of the GM12878 subtypes.  There were still however 25118 sites unaccounted for.  These other ones have no annotation in the merged file.  I am going to keep these unknown sites in the analysis and investigate later where they came from.

2. I used grep to remove any lines which contained an "Hlspecific annotation".  I will then run the same script as that which was used originally (*scATACseq_subsetmergedCtl.py*) and not the modified version to remove any sites with usage in < 150 cells.  Thus I am only eliminating HL-60 specific sites and retaining the Common, GM12878-specific, and un-annotated sites in the file.  I may try later again with removal of the un-annotated sites. The only modification to the file was changing the filenames to use the *CtlSetMerged.dhsmatrix_dataonly_noHL.txt* file. There were 132439 sites in this file prior to row reduction, and there are 30131 sites in the output.

3. Created two new R scripts which are modifications of the original R script for t-sne and MDS clustering on Jaccard distances.  Both now take the R binary file of distance matrices as input.  In addition, one file is meant for the GM12878-only matrix with sparse rows/columns removed.  It can be used with the file containing all sites and the file containing no HL-60 specific sites, and later the file without the un-annotated sites.  The other is meant for the HL-60 and GM12878 cell mixture with sparse rows/columns removed.  They are named *scATAC_jaccardtsneMDS_RDSinput_GMsubtypes.R* and *scATAC_jaccardtsneMDS_RDSinput_HLvsGM.R* respectively.

4. Created file *CtlSetMerged.dhsmatrix.GMfullyreduced_noHL.csv* by subsetting columns in R which were non-GM12878 and which used < 400 sites.  Uploaded this file on the server and submitted job to produce new distance matrices for both sites and cells.  Also created new bed file of the sites retained *CtlSetMerged.dhsmatrix.GMfullyreduced_noHL.sites.bed* and merged with chromHMM annotations to produce file *CtlSetMerged.dhsmatrix.GMfullyreduced_noHL.annotated_sites.bed* using the command:
```
bedtools intersect -a CtlSetMerged.dhsmatrix.GMfullyreduced_noHL.sites.bed -b hg19chromHMM.bed \
-wa -wb  > CtlSetMerged.dhsmatrix.GMfullyreduced_noHL.annotated_sites.bed
```

This actually wasn't totally necessary since the noHL site set should be a subset of the other annotated site file for all sites in the GMfullyreduced matrix.

5. Had to create new CtlSetMerged.dhsmatrix.fullyreduced.csv because it seems I forgot to add the coordinate columns at the beginning of the file. Created new annotated sites file for GM12878 and HL-60 mixture (this is actually necessary, since some sites may be retained in this file which were not retained in the GMfullyreduced set). Used the following command:

```
bedtools intersect -a CtlSetMerged.dhsmatrix.fullyreduced.sites.bed -b ../hg19chromHMM.bed \
-wa -wb  > CtlSetMerged.dhsmatrix.fullyreduced.annotated_sites.bed
```

6. Realized that I have exactly the same number of sites retained in HL-60/GM12878 mixture as I do in the GM12878-only file.  There is a mistake in my python script to remove sites which are used in < 150 cells: I am considering both HL-60 and GM12878 cells, so when I want to only look at GM12878 I should be doing a second subset in R to again remove additional rows which have a sum of < 150.  I will have to re-create the GMfullyreduced files both containing HL-60 sites and not, and then I will have to recreate the distance matrices for both. I have decided to just run the same script on the GMfullyreduced file because this should only do additional subsetting.  I will not have to again remove non-GM12878 so I left this line commented out in the *scATAC_mergedctlsubset.R* script. This worked exactly as it should: I now have 16219 retained rows and the same number of retained columns, 4705.  Here is the subset I performed:

```
keepcols = (colSums(DHSmatrix) >= 400)
keeprows = (rowSums(DHSmatrix) >= 150)
DHSmatrix = subset(DHSmatrix,subset=keeprows,select=keepcols)
```
and some edits to the next part of the code because we are now removing rows in this script, whereas indexing wasn't a problem before:

```
#to create bed coordinates before merging back to original data matrix
DHSmatrix1 = fread('CtlSetMerged.dhsmatrix.GMfullyreduced.csv',
             header=F,stringsAsFactors = F,sep =" ")
DHSmatrix1 = DHSmatrix1[,1:3]
DHSmatrix1 = subset(DHSmatrix1,subset=keeprows)
DHSmatrix1 = cbind(DHSmatrix1, rep("+",16219))
```
This was done for the file above, *CtlSetMerged.dhsmatrix.GMfullyreduced.csv*, and *CtlSetMerged.dhsmatrix.GMfullyreduced_noHL.csv*; The only difference is the number '16219' in the last line, which is the number of retained rows.
Also need to check indexing on the merging of sites coordinates with the reduced matrix for the completed and correct matrices (skip=1 in the second fread, and I am not sure why I had to have it like this).

7. In order to produce t-sne and MDS plots of the cell-type mixtures based on cell-type, I took a snippet of code from the *scATAC_mergedctlsubset.R* script to output a vector of the retained barcodes.  Then discovered that somehow the distance matrix had been created for the wrong file: it seems that I made the distance matrix for the GM12878 subset instead of the mixture because there were only 4705 cells; this was probably a mistake in the shell script or R script, which has since been erased.  Had to remake the distance matrix on the server.  So there are currently 3 jobs running on the server to make cell/site distance matrices for GM12878 and HL-60 mixture, GM12878-only with all sites, and GM12878-only with no HL-60 specific sites (except for the mixture I am just making the cell file first).

8. The jobs on the server are complete for creating distance matrices as .RDS files for GM12878-only with all sites and GM12878-only with no HL-60 specific sites.  The mixture is continuining to run.

9. I created a script to produce a NMF model from the *CtlSetMerged.dhsmatrix.GMfullyreduced.csv* matrix.  I was able to cluster and produce an approximated matrix.  So far, this approximated matrix looks like it may be a good candidate for reducing sparsity and producing an "accessibility" score; there are very small numbers but I haven't seen any 0's in the matrix.  I haven't been able to produce a heatmap yet but there should be one soon.

##February 1
1. Wrote a python script to create a heatmap from the output of **scATAC_NMF_mergedCtl.R**.  The file it takes as input is the reconstructed target matrix from NMF sorted in the order of the NMF clusters. May have to edit NMF script because output heatmap appears to cluster a bit strangely: there are many rows in the heatmap which appear should be clustered together but aren't.  In general, there are identifiable clusters of cells and sites.  Ideally I should use the estimate rank function or cross validation to estimate rank, and in the future I will create this plot with rank = number of modules identified in Cusanovich et al. The following is the plot for GM12878 subtypes clustering including all DHS sites:

![Heatmap of reconstructed target matrix from NMF with rank=4, where rows and columns are sorted according to their cluster membership in NMF. The color range in the heatmap was capped at .2 although the actual entried extended beyond 7.  This was because these large outliers prevented visualization of the clusters using the colors in the map.](/Users/cass/Documents/LeslieLab/NewAnalysis/GM12878subtypes_NMF4.png)

2. Created the NMF heatmap using the same python script.  Used an editted version of the script to be run from command line as follows:

```
python ../Git_Repo/scATAC-seq/scATAC_NMFheatmap.py CtlSetMerged_DHSmatrix_GM12878only/NoHLSites/CtlSetMerged.dhsmatrix.GMfullyreduced_noHL.NMF4clustered.txt CtlSetMerged_DHSmatrix_GM12878only/NoHLSites/CtlSetMerged.dhsmatrix.GMfullyreduced_noHL.NMF4clustered.png
```

The resulting heatmap also had identifiable clusters.  I believe that this heatmap is more appropriate then the previous one for more theoretical considerations.  With NMF, it is difficult to compare the results with all sites vs. with no HL-60 specific sites because the heatmap has a different number of features in each case, and so naturally it will not look the same.  I will use t-sne and MDS tomorrow to really assess whether the inclusion of HL-60-specific sites has any non-trivial effect on the performance of clustering.  Below is the heatmap image:

![]()

It should be noted that for this heatmap, I simply used 0 as the the lower limit for the color scale whereas in the previous image I used the minimum value (which was so close to 0 that it hardly matters).  Both images had the upperbound on the color bar set to .2.  This is very noteworthy: this means that any cell with value of .2 or greater is displayed the same (as the dark blue color) on the heatmap.  The rationale for this was that there were outliers that, when included, would make it appear as though the entire heatmap was uniform except for these outliers.  This color scaling allows for an emphasis of small effects between numbers, and makes apparent the clusters in the data.  The value .2 was arbitrarily chosen because the clusters were highly apparent with this parameter.

##February 2nd
1. I believe that to solve the clustering problem with NMF, I can do two different things: 1) I can cluster the rows according to the row clusters when rank = number of sites in LSA while using the original columns clustering, and 2) I can cluster the rows with simple heirarchical clustering and cluster the columns with the original NMF column clustering.


##February 3rd-7th
1. I realized my script was a little bit too conservative in filtering out sites and cells which are too sparse.  The issue is that in passing the script with some rows already filtered, more columns are removed because fewer rows are there to begin with.  Ideally, the row and columns subsetting should occur simultaneously.  In the future this will be fixed but it should not impact the results.  It just makes my filtering slightly more conservative.  The loss of cells must have been minimal since I still had around the same number of cells in the end as that which was used in the paper.

2. **NMF Results**:  Completed NMF for the following datasets-rank combinations: GM12878 Subtypes (no HL-60 sites) with Ranks 4 and 7, and GM12878/HL-60 Mixture with Rank 2.  

3. **LSA Results**: Completed LSA on GM12878 Subtypes for all DHS sites and without HL-60 sites.  Chose to focus on the set without HL-60 sites for two reasons. One, this is intuitively the more accurate dataset for identifying site clusters across GM12878 subtypes.  Two, the 'row reduced' file for the GM12878 subtype DHS matrix will all sites was somehow deleted, which means I no longer have a mapping between barcodes and columns for this.  I will have to remake this file if I ever want to use this dataset again.

4. Began ChIP-seq transcription factor binding site enrichment in GM12878 subtype site clusters.  I downloaded as a batch all GM12878 ChIP-seq datasets available on ENCODE in the narrow-peak bed format on the server using the following command from ENCODE's website, where 'files.txt' was also generated from their website:
```
xargs -n 1 curl -O -L < files.txt
```
 I uploaded a bed file onto the server which contains all the non-HL60 sites and their cluster assignments from heirarchical clustering on the LSA matrix reconstructed with components 2-6, as this was the most promising clustering obtained from benchmarking (based on the lack of correlation with read depth among cells).  Cluster membership was extracted using cutree() in R at a height decided by visual inspection to closely match the relative level used in Cusanovich et al. (everything described is in the scATAC_LSA_mergedCtl.R script).  This bed file was intersected with all the ChIP bed files with the following command:
 
```
bedtools intersect -a CtlSetMerged.dhsmatrix.GMfullyreduced_noHL.SVD2_6_siteclusters.bed -b *.gz -wo -filenames > CtlSetMerged.dhsmatrix.GMfullyreduced_noHL.SVD2_6_siteclusters_CHiP.bed
```

5. Before beginning GO analysis, noted this excerpt from González et al. 2015 (the paper on early enhancer establishment from Christina's lab):

"The June 2013 RefSeq transcript annotation of the hg19 version of the human genome was used for the genomic location of transcription units. For genes with multiple gene models, the longest transcription unit was used for the gene locus definition. DNase peaks located in the body of the transcription unit, together with the 2-kb regions upstream of the TSS and downstream of the 3′ end, were assigned to the gene. If a peak was found in the overlap of the transcription units of two genes, one of the genes was chosen arbitrarily. Intergenic peaks were assigned to the gene whose TSS or 3′ end was closest to the peak. In this way, each peak was unambiguously assigned to one gene. This approach to associating enhancers with target genes has been used previously"

I will attempt to follow this procedure as closely as possible.

6. Performed GO analysis using the procedure above to assign sites to genes..

##February 8
1. Found this excerpt online about how to compute "document similarity" with LSA:

"say, you want to determine the similarity between document i and j. take the i-th column of V^t (=d_i) and j-th column of V^t (=d_j)

take the cosine similarity of diag(S)*d_i and diag(S) * d_j

the closer this is to +1, the more they are similar"

It is my suspicion that I can do the "transpose" of this to compute "word similarity" (or in my case, site similarity).  Paper "Using latent semantic analysis to estimate similarity" by Sabrina Simons confirms that cosine difference between each words vector should be used.